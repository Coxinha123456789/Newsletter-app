import streamlit as st
import pandas as pd
import requests
import json

# --- BIBLIOTECAS NECESS√ÅRIAS ---
try:
    import google.generativeai as genai
    from GoogleNews import GoogleNews
    from pydantic import BaseModel, Field
    from typing import List
except ImportError as e:
    st.error(f"""
        Uma ou mais bibliotecas necess√°rias n√£o foram encontradas.
        Por favor, instale a biblioteca de busca de not√≠cias executando:

        pip install GoogleNews

        E as outras depend√™ncias, se necess√°rio:
        pip install streamlit pandas requests google-generativeai pydantic

        Erro original: {e}
    """)
    st.stop()

# --- CHAVES DE API ---
try:
    JINA_API_KEY = st.secrets["JINA_API_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except (KeyError, FileNotFoundError):
    st.error("Erro: Chaves JINA_API_KEY ou GEMINI_API_KEY n√£o encontradas. Verifique seu arquivo .streamlit/secrets.toml.")
    st.stop()


# --- SUA FUN√á√ÉO DE BUSCA RESTAURADA ---
def buscar_google_news(termo):
    # Inicializa o objeto GoogleNews
    googlenews = GoogleNews(lang='pt-BR', period='7d', encode='utf-8')

    # Realiza a busca com o termo do usu√°rio
    googlenews.search(termo)

    # --- SEU C√ìDIGO DE PAGINA√á√ÉO REINSERIDO AQUI ---
    # Define o n√∫mero m√°ximo de resultados desejados
    max_resultados = 2000
    resultados = []
    pagina = 1

    # Itera sobre as p√°ginas de resultados at√© atingir o n√∫mero desejado
    # Adicionado um status para o usu√°rio ver o progresso da busca longa
    status_text = st.empty()
    while len(resultados) < max_resultados:
        status_text.text(f"Buscando not√≠cias... P√°gina {pagina}, {len(resultados)} resultados encontrados.")
        googlenews.get_page(pagina)
        noticias_pagina = googlenews.result(sort=True) # Usar sort=True pode ajudar na ordem
        if not noticias_pagina:
            break  # Encerra se n√£o houver mais resultados
        resultados.extend(noticias_pagina)
        pagina += 1
    status_text.empty()

    # Limita a lista de resultados ao n√∫mero m√°ximo desejado
    resultados = resultados[:max_resultados]
    
    if not resultados:
        return pd.DataFrame()

    # Exibe os resultados no console
    quantidade_noticias = len(resultados)
    print(f'Quantidade de not√≠cias retornadas: {quantidade_noticias}')

    # Coloca todas as noticias num dataframe
    df = pd.DataFrame(resultados)
    
    # Limpeza e formata√ß√£o do DataFrame
    df['link'] = df['link'].str.split('&ved').str[0]
    df.rename(columns={'media': 'source'}, inplace=True)

    # Garante que as colunas essenciais existam antes de retornar
    colunas_necessarias = {'title', 'link', 'source'}
    if not colunas_necessarias.issubset(df.columns):
        st.warning("A busca n√£o retornou as colunas esperadas (title, link, source).")
        return pd.DataFrame()

    return df[['title', 'link', 'source']]


# --- FUN√á√ÉO 'PEGA_NOTICIAS' (COM CACHE) ---
@st.cache_data(ttl=3600)
def pega_noticias(termo_busca):
    """Busca not√≠cias, combina e remove duplicatas."""
    # O spinner agora envolve a chamada da fun√ß√£o que pode ser longa
    with st.spinner("Realizando busca aprofundada de not√≠cias... Isso pode levar alguns minutos."):
        todas_as_noticias = buscar_google_news(termo_busca)

    if todas_as_noticias.empty:
        return pd.DataFrame()

    # Limpa e remove duplicatas
    todas_as_noticias.dropna(subset=['link'], inplace=True)
    noticias_unicas = todas_as_noticias.drop_duplicates(subset=['link'], keep='first')
    noticias_unicas = noticias_unicas.drop_duplicates(subset=['title'], keep='first')
    noticias_unicas.reset_index(drop=True, inplace=True)
    
    st.success(f"Busca conclu√≠da! {noticias_unicas.shape[0]} not√≠cias √∫nicas encontradas.")
    return noticias_unicas


# --- FUN√á√ÉO DE EXTRA√á√ÉO DE CONTE√öDO (INTOCADA) ---
@st.cache_data(ttl=3600)
def extrair_conteudo_noticias(df_noticias):
    # (O c√≥digo desta fun√ß√£o permanece o mesmo)
    conteudos = []
    headers = {"Authorization": f"Bearer {JINA_API_KEY}", "X-Engine": "browser"}
    total_noticias = len(df_noticias)
    progress_bar = st.progress(0)
    status_text = st.empty()
    for i, (index, row) in enumerate(df_noticias.iterrows()):
        status_text.text(f"Extraindo not√≠cia {i + 1}/{total_noticias}: {row['title'][:50]}...")
        url = f"https://r.jina.ai/{row['link']}"
        try:
            response = requests.get(url, headers=headers, timeout=20)
            response.raise_for_status()
            conteudos.append(response.text)
        except requests.exceptions.RequestException as e:
            conteudos.append(f"Erro ao buscar conte√∫do para o t√≠tulo '{row['title']}': {e}")
        progress_bar.progress((i + 1) / total_noticias)
    status_text.empty()
    return pd.DataFrame({'title': df_noticias['title'], 'link': df_noticias['link'], 'content': conteudos})

# --- FUN√á√ÉO GEMINI (INTOCADA) ---
@st.cache_data(ttl=3600)
def processa_noticias_com_gemini(df_conteudos):
    # (O c√≥digo desta fun√ß√£o permanece o mesmo)
    respostas_json = []
    links_originais = df_conteudos['link'].tolist()
    for i, texto in enumerate(df_conteudos['content']):
        if texto.startswith("Erro ao buscar conte√∫do"):
            respostas_json.append(json.dumps({"titulo": "Conte√∫do da not√≠cia n√£o dispon√≠vel"}))
            continue
        try:
            model = genai.GenerativeModel(model_name="gemini-1.5-pro-latest")
            response = model.generate_content(
                f"""
                Analise o seguinte texto de uma not√≠cia e extraia as informa√ß√µes no formato JSON.
                O JSON deve seguir a seguinte estrutura:
                {{
                    "titulo": "O t√≠tulo da not√≠cia.",
                    "data_de_publicacao": "A data em que a not√≠cia foi publicada (se dispon√≠vel).",
                    "resumo_curto": "Um resumo conciso da not√≠cia, apensa com o assunto principal da noticia, n√£o precisa enrolar muito, apenas o basico para um usuario entender do que se trata a noticia, entre 30 palavras e 50 palavras.",
                    "resumo_maior": "Um resumo mais detalhado da not√≠cia, apenas com as informa√ß√µes mais relevantes da noticia e algumas observa√ß√µes a mais, com mais de 150 palavras.",
                    "links_de_imagens": ["Uma lista contendo at√© 2 URLs das imagens mais relevantes da not√≠cia. Se n√£o houver, retorne uma lista vazia."]
                }}
                Texto da not√≠cia:
                ---
                {texto}
                """,
                generation_config={"response_mime_type": "application/json"}
            )
            noticia_processada = json.loads(response.text)
            noticia_processada['link'] = links_originais[i]
            respostas_json.append(json.dumps(noticia_processada, ensure_ascii=False))
        except Exception as e:
            print(f"Erro ao processar not√≠cia com Gemini: {e}")
            respostas_json.append(json.dumps({"titulo": "Conte√∫do da not√≠cia n√£o dispon√≠vel"}))
    return respostas_json

# --- FUN√á√ÉO DE RENDERIZA√á√ÉO (INTOCADA) ---
def gerar_newsletter_streamlit(lista_json):
    # (O c√≥digo desta fun√ß√£o permanece o mesmo)
    if not lista_json:
        st.info("Nenhuma not√≠cia processada para exibir.")
        return
    noticias_exibidas = 0
    for i, noticia_str in enumerate(lista_json):
        try:
            noticia = json.loads(noticia_str)
            if not noticia or noticia.get("titulo") == "Conte√∫do da not√≠cia n√£o dispon√≠vel":
                continue
        except (json.JSONDecodeError, AttributeError):
            continue
        titulo = noticia.get("titulo", "T√≠tulo n√£o encontrado")
        data = noticia.get("data_de_publicacao", "Data n√£o informada")
        resumo_curto = noticia.get("resumo_curto", "")
        resumo_maior = noticia.get("resumo_maior", "")
        link = noticia.get("link", "#")
        imagens = noticia.get("links_de_imagens", [])
        imagem = imagens[0] if imagens else "https://via.placeholder.com/400x267?text=Sem+Imagem"
        with st.container(border=True):
            col_img, col_content = st.columns([1, 3])
            with col_img:
                st.image(imagem)
            with col_content:
                st.subheader(titulo)
                st.caption(f"Publicado em: {data}")
                st.write(resumo_curto)
                if resumo_maior:
                    with st.expander("Ler resumo completo..."):
                        st.write(resumo_maior)
                st.markdown(f'<a href="{link}" target="_blank" style="color: #0a9396; font-weight: bold;">Ler not√≠cia completa ‚Üó</a>', unsafe_allow_html=True)
        noticias_exibidas += 1
    st.write(f"**Exibindo {noticias_exibidas} not√≠cias processadas.**")

# --- INTERFACE PRINCIPAL DO STREAMLIT (INTOCADA) ---
st.set_page_config(page_title="Gerador de Newsletter com IA", layout="centered")
st.title("üì∞ Gerador de Newsletter com IA")
st.markdown("Digite um tema, clique em gerar e obtenha um resumo das √∫ltimas not√≠cias do Google News, processado por Intelig√™ncia Artificial.")

termo_busca = st.text_input("Qual tema voc√™ quer pesquisar?", placeholder="Ex: Novidades sobre o clima")

if st.button("Gerar Newsletter", type="primary"):
    if not termo_busca:
        st.warning("Por favor, digite um termo para a busca.")
    else:
        df_noticias = pega_noticias(termo_busca)
        if not df_noticias.empty:
            df_conteudos = extrair_conteudo_noticias(df_noticias)
            with st.spinner("A Intelig√™ncia Artificial est√° analisando e resumindo as not√≠cias..."):
                resumos_json = processa_noticias_com_gemini(df_conteudos)
            st.success("Newsletter gerada com sucesso!")
            st.markdown("---")
            gerar_newsletter_streamlit(resumos_json)
        else:
            st.error(f"Nenhuma not√≠cia encontrada no Google News para o termo '{termo_busca}'. Tente outra palavra-chave.")
