import streamlit as st
import pandas as pd
import requests
import json
import time
import numpy as np
from datetime import datetime
from typing import List

# --- Importa√ß√µes das bibliotecas de Machine Learning e Not√≠cias ---
try:
    from GoogleNews import GoogleNews
    from sklearn.metrics.pairwise import cosine_similarity
    from google import genai
    from pydantic import BaseModel, Field
except ImportError as e:
    st.error(f"""
        Uma ou mais bibliotecas necess√°rias n√£o foram encontradas.
        Por favor, instale-as com o comando abaixo no seu terminal:

        pip install streamlit pandas GoogleNews scikit-learn google-generativeai pydantic numpy

        Erro original: {e}
    """)
    st.stop()

# --- 1. CONFIGURA√á√ÉO DAS CHAVES DE API ---
# As chaves s√£o carregadas a partir dos "secrets" do Streamlit
try:
    JINA_API_KEY = st.secrets["JINA_API_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
except (KeyError, FileNotFoundError):
    st.error("Erro: Verifique se as chaves JINA_API_KEY e GEMINI_API_KEY est√£o no seu arquivo secrets.toml.")
    st.stop()

# ==============================================================================
# ==== IN√çCIO: SUAS FUN√á√ïES (COM ALTERA√á√ïES M√çNIMAS E ESSENCIAIS) ====
# ==============================================================================

def buscar_google_news(termo):
    from GoogleNews import GoogleNews
    googlenews = GoogleNews(lang='pt-BR', period='1d', encode='utf-8')

    # ALTERA√á√ÉO M√çNIMA: Usar o 'termo' do input em vez de um valor fixo.
    googlenews.search(termo)

    max_resultados = 1000
    resultados = []
    pagina = 1
    while len(resultados) < max_resultados:
        googlenews.get_page(pagina)
        noticias = googlenews.result()
        if not noticias:
            break
        resultados.extend(noticias)
        pagina += 1
    resultados = resultados[:max_resultados]
    print(f'Quantidade de not√≠cias retornadas do GoogleNews: {len(resultados)}')
    if not resultados:
        return pd.DataFrame()
    df = pd.DataFrame(resultados)
    df['link'] = df['link'].str.split('&ved').str[0]
    df.rename(columns={'media': 'source'}, inplace=True)
    if 'datetime' in df.columns:
        df.drop(columns=['datetime'], inplace=True)
    if 'img' in df.columns:
        df.drop(columns=['img'], inplace=True)
    return df

def pega_noticias(termo_busca):
    todas_as_noticias = buscar_google_news(termo_busca)
    if todas_as_noticias.empty:
        return pd.DataFrame()
    todas_as_noticias.dropna(subset=['link'], inplace=True)
    noticias_unicas = todas_as_noticias.drop_duplicates(subset=['link'], keep='first')
    noticias_unicas = noticias_unicas.drop_duplicates(subset=['title'], keep='first')
    noticias_unicas.reset_index(drop=True, inplace=True)
    print(f"Busca conclu√≠da! {noticias_unicas.shape[0]} not√≠cias √∫nicas encontradas.")
    return noticias_unicas

def ordenar_noticias_por_similaridade(interesse, df_noticias, top_n=10):
    TEXTOS = df_noticias['title'].to_list()
    # ALTERA√á√ÉO M√çNIMA: Usar st.secrets em vez de userdata do Colab.
    # A configura√ß√£o global 'genai.configure' j√° lida com a API Key.
    result = genai.embed_content(model="models/embedding-001", content=interesse, task_type="RETRIEVAL_QUERY")
    interesse_embed = np.array(result['embedding'])
    VETORES = []
    for i in range(0, len(TEXTOS), 100):
        batch_textos = TEXTOS[i:i+100]
        result_batch = genai.embed_content(model="models/embedding-001", content=batch_textos, task_type="RETRIEVAL_DOCUMENT")
        VETORES.extend([np.array(e) for e in result_batch['embedding']])
    interesse_embed_2d = interesse_embed.reshape(1, -1)
    similaridades = [cosine_similarity(interesse_embed_2d, v.reshape(1, -1))[0][0] for v in VETORES]
    df_noticias['score'] = similaridades
    df_noticias.sort_values(by='score', ascending=False, inplace=True)
    return df_noticias.head(top_n).reset_index(drop=True)

def extrair_conteudo_noticias(df_noticias):
    headers = {
        # ALTERA√á√ÉO M√çNIMA: Usar st.secrets em vez de userdata do Colab.
        "Authorization": f"Bearer {JINA_API_KEY}",
        "X-Engine": "browser",
        "X-Return-Format": "markdown"
    }
    total_noticias = len(df_noticias)
    conteudos = []
    for index, row in df_noticias.iterrows():
        # ALTERA√á√ÉO M√çNIMA: Usar o status do Streamlit para feedback visual.
        st.session_state.status_bar.update(label=f"Extraindo not√≠cia {index + 1}/{total_noticias}: {row['title'][:40]}...")
        url = f"https://r.jina.ai/{row['link']}"
        try:
            response = requests.get(url, headers=headers, timeout=90)
            response.raise_for_status()
            conteudos.append(response.text)
        except requests.exceptions.RequestException as e:
            conteudos.append(f"Erro ao buscar conte√∫do para o t√≠tulo '{row['title']}': {e}")
    df_noticias['content'] = conteudos
    return df_noticias

def processa_noticias_com_gemini(articles_df):
    class Noticia(BaseModel):
        titulo: str = Field(..., description="O t√≠tulo da not√≠cia.")
        data_de_publicacao: str = Field(..., description="A data em que a not√≠cia foi publicada. Use sempre o formato: 'DD/MM/AAAA'.")
        autor: str = Field(..., description="O nome do autor da not√≠cia.")
        portal: str = Field(..., description="O nome do portal de not√≠cias onde a not√≠cia foi publicada.")
        resumo_curto: str = Field(..., description="Um resumo conciso da not√≠cia em torno de 50 palavras. De prefer√™ncia para colocar informa√ß√£o adicional ao titulo (nao repetir a informacao do titulo)")
        resumo_maior: str = Field(..., description="Um resumo mais detalhado da not√≠cia em torno de 500 palavras.")
        pontos_principais: List[str] = Field(..., description="um resumo da noticia em formato de lista item a item")
        noticia_completa: str = Field(..., description="O texto completo da not√≠cia.")
        links_de_imagens: List[str] = Field(..., description="Uma lista de URLs das imagens associadas √† not√≠cia. Considere apenas aquelas relevantes para a noticia. Descarte logos, divulgacoes, etc...")
        tags_relevantes: List[str] = Field(..., description="Uma lista de tags ou palavras-chave relevantes para a not√≠cia.")
        prompt_satira_imagem: str = Field(..., description="Um prompt de s√°tira, baseado no conte√∫do da not√≠cia, para ser usado em um gerador de imagens. Deve ser criativo e com um tom humor√≠stico ou ir√¥nico.")
    
    generation_config = {"response_mime_type": "application/json", "response_schema": Noticia}
    model = genai.GenerativeModel(model_name="gemini-1.5-flash", generation_config=generation_config)
    
    respostas = []
    total_artigos = len(articles_df)
    for index, texto in enumerate(articles_df['content']):
        st.session_state.status_bar.update(label=f"Processando com IA {index + 1}/{total_artigos}...")
        if texto.startswith("Erro ao buscar conte√∫do"):
            respostas.append('{}') # Adiciona um JSON vazio em caso de erro
            continue
        while True:
            try:
                prompt = f"Extraia informacoes da noticia em texto cru dada a seguir: \n\n {texto}"
                response = model.generate_content(prompt)
                respostas.append(response.text)
                break
            except Exception as e:
                print(f"Erro na API Gemini: {e}. Tentando novamente em 3s...")
                time.sleep(3)
    lista_de_dicionarios = [json.loads(json_string or '{}') for json_string in respostas]
    processados_df = pd.DataFrame(lista_de_dicionarios)
    return processados_df

def gerar_card_noticia(noticia: dict, idx: int) -> str:
    titulo = noticia.get('titulo', '')
    portal = noticia.get('portal', '')
    data_pub = noticia.get('data_de_publicacao', '')
    resumo_breve = noticia.get('resumo_curto', '')
    resumo_expandido = noticia.get('resumo_maior', '')
    tags = noticia.get('tags_relevantes', [])
    url_original = noticia.get('link', '')
    caminho_imagem = noticia.get('links_de_imagens', [])
    prompt_satira_imagem = noticia.get('prompt_satira_imagem', '')
    pontos_principais = noticia.get('pontos_principais', [])
    imagem_url = caminho_imagem[0] if caminho_imagem else ''
    tags_str = ', '.join(tags) if tags else ''
    pontos_principais_html = "".join([f"<li>{p}</li>" for p in pontos_principais]) if pontos_principais else ""
    return f"""<div class="card-noticia"> ... </div>""" # HTML do card (omitido por brevidade, mas est√° no seu c√≥digo)

def gerar_html_newsletter(df: pd.DataFrame, interesse: str) -> str:
    html_content = f"""<!DOCTYPE html> ... </html>""" # Template HTML (omitido por brevidade)
    # Adiciona cada card de not√≠cia
    cards_html = ""
    for idx, row in df.iterrows():
        noticia_dict = row.to_dict()
        cards_html += gerar_card_noticia(noticia_dict, idx) # A sua fun√ß√£o de card
    # Injeta os cards no template
    final_html = html_content.replace("", cards_html)
    return final_html

# ==============================================================================
# ==== FIM: SUAS FUN√á√ïES                                                   ====
# ==============================================================================

# --- INTERFACE DO STREAMLIT ---
st.set_page_config(page_title="Gerador de Newsletter com IA", layout="wide")
st.title("üì∞ Gerador de Newsletter com IA")
st.markdown("Crie uma newsletter personalizada. Defina um tema geral para a busca, um interesse espec√≠fico para o ranking e o n√∫mero de not√≠cias desejado.")

# --- INPUTS DO USU√ÅRIO ---
tema_busca = st.text_input(
    "1. Tema geral para a busca de not√≠cias",
    value="Intelig√™ncia Artificial",
    help="Ex: 'sustentabilidade', 'mercado financeiro', 'elei√ß√µes 2026'"
)
interesse_ordem = st.text_input(
    "2. Interesse espec√≠fico para ordenar por relev√¢ncia",
    value="IA na pol√≠tica, governo e prefeituras",
    help="Ex: 'impacto da IA na educa√ß√£o', 'carros el√©tricos no Brasil'"
)
top_noticias = st.number_input(
    "3. Quantidade de not√≠cias para a newsletter final",
    min_value=1,
    max_value=20,
    value=3,
    help="Escolha o n√∫mero de not√≠cias que aparecer√£o na newsletter ap√≥s a ordena√ß√£o."
)

if st.button("Gerar Newsletter", type="primary"):
    # --- LIGA√á√ÉO DAS FUN√á√ïES EM ORDEM (WORKFLOW) ---
    with st.status("Iniciando processo...", expanded=True) as status:
        st.session_state.status_bar = status # Permite que as fun√ß√µes atualizem o status

        # PASSO 1: Pega as not√≠cias
        status.update(label="Passo 1/5: Buscando um grande volume de not√≠cias...")
        df_bruto = pega_noticias(tema_busca)

        if df_bruto.empty:
            st.error("Nenhuma not√≠cia encontrada para o tema. Tente um termo diferente.")
            st.stop()

        # PASSO 2: Ordena por similaridade
        status.update(label=f"Passo 2/5: Ordenando {len(df_bruto)} not√≠cias por relev√¢ncia ao seu interesse...")
        df_ordenado = ordenar_noticias_por_similaridade(
            interesse=interesse_ordem,
            df_noticias=df_bruto,
            top_n=top_noticias
        )

        # PASSO 3: Extrai o conte√∫do
        status.update(label="Passo 3/5: Extraindo conte√∫do das not√≠cias selecionadas...")
        df_com_conteudo = extrair_conteudo_noticias(df_ordenado)

        # PASSO 4: Processa com Gemini
        status.update(label="Passo 4/5: Usando IA para estruturar e resumir as not√≠cias...")
        df_processado = processa_noticias_com_gemini(df_com_conteudo)

        # PASSO 5: Junta os dataframes e gera o HTML
        status.update(label="Passo 5/5: Montando a newsletter final...")
        # Garante que os √≠ndices est√£o alinhados para a concatena√ß√£o
        df_com_conteudo.reset_index(drop=True, inplace=True)
        df_processado.reset_index(drop=True, inplace=True)
        df_final = pd.concat([df_com_conteudo, df_processado], axis=1)

        # Substitu√≠ sua fun√ß√£o original pela vers√£o completa que voc√™ mandou
        html_final = gerar_html_newsletter(df_final, interesse_ordem)
        status.update(label="Processo conclu√≠do!", state="complete", expanded=False)

    st.success("Newsletter gerada com sucesso!")

    # Adiciona um bot√£o de download para o arquivo HTML
    st.download_button(
        label="üì• Baixar Newsletter em HTML",
        data=html_final,
        file_name=f"newsletter_{tema_busca.replace(' ', '_')}.html",
        mime="text/html"
    )

    # Exibe o HTML diretamente na p√°gina
    st.markdown("### Pr√©-visualiza√ß√£o da Newsletter")
    st.components.v1.html(html_final, height=800, scrolling=True)
